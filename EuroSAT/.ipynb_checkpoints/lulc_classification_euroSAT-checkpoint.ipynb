{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2180c19",
   "metadata": {},
   "source": [
    "# Import the essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"OS: Operating system-related functions. Glob: File path pattern matching.\"\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "# Python library for creating visualizations and plots in data analysis.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Python package for numerical computations and array operations.\n",
    "import numpy as np\n",
    "\n",
    "# Tensorflow package for constructing ResNet50 model in Python.\n",
    "import tensorflow.python.keras as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "'''\n",
    "itertools: Python package for efficient iteration and combinatorial operations.\n",
    "sklearn: Python package for machine learning and data analysis.\n",
    "metrics: Python package for evaluating model performance and statistical metrics.\n",
    "'''\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# For visualization of plots without plt.show()\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__ #retrieve the version number of the TensorFlow library installed in the current environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6df6d9",
   "metadata": {},
   "source": [
    "# Define the required variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of the validation and training dataset located\n",
    "dataset_url = r'C:\\Users\\HP\\Downloads\\SoftDev assignment 3\\Assignment 3\\EuroSAT\\2750'\n",
    "size_batch = 32\n",
    "height_img = 64\n",
    "width_img = 64\n",
    "validation_split=0.2 #Parameter to split data for validation during model training in Keras.\n",
    "rescale=1.0/255 # rescaling input data to a specified range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefdf9d",
   "metadata": {},
   "source": [
    "# Data preparation for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4902df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorFlow package for generating augmented image data for deep learning.\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_split, rescale=rescale)\n",
    "\n",
    "#Create TensorFlow image dataset from directory with preprocessing using Keras.\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_url, image_size=(height_img, width_img), batch_size=size_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f535e97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data iterator from a directory of images to generate training dataset.\n",
    "train_dataset = datagen.flow_from_directory(batch_size=size_batch,\n",
    "                                           directory=dataset_url,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(height_img, width_img),\n",
    "                                           subset=\"training\",\n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f208eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data iterator from a directory of images to generate test dataset.\n",
    "test_dataset = datagen.flow_from_directory(batch_size=size_batch,\n",
    "                                           directory=dataset_url,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(height_img, width_img),\n",
    "                                           subset=\"validation\",\n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76070a",
   "metadata": {},
   "source": [
    "# Visualization of input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ac666",
   "metadata": {},
   "source": [
    "# ResNet50 Model building\n",
    "\n",
    "##### ResNet50 Architecture\n",
    "![resnet50](./img/resnet50.png)\n",
    "\n",
    "###### ResNet Identity block\n",
    "![identity block](./img/idblock.png)\n",
    "\n",
    "###### ResNet Convolution Block\n",
    "![conv block](./img/convblock.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    The purpose of the identity_block function is to learn and extract complex patterns \n",
    "    and hierarchical representations from input data while preserving the spatial dimensions \n",
    "    of the input. It achieves this by stacking multiple layers of convolution, batch \n",
    "    normalization, and activation functions.\n",
    "    \n",
    "    \n",
    "    Implementation of the identity block\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value.\n",
    "    X_shortcut = X\n",
    "    cache = []\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = X = Activation('relu')(X, training = training)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
    "                   also called Xavier uniform initializer.\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "   \n",
    "   The purpose of the convolutional_block function is to stack multiple convolutional layers, with optional batch \n",
    "   normalization and activation functions, to learn and extract meaningful features from input data. This function \n",
    "   helps in capturing complex patterns and hierarchical representations present in the data.\n",
    "   \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    \n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(F2, (f, f), strides = (1, 1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(F3, (1, 1), strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), padding = 'valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training)\n",
    "\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d013bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "   # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size = (2, 2), name = 'avg_pool')(X)\n",
    "    \n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d50885",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1baf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape=(64,64,3), classes=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc912ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d3df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# please increase the epoch for higher accuracy (epochs=100)\n",
    "history = model.fit(train_dataset, validation_data=test_dataset, epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'model/model_3_epoch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883fb83",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67618913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(r\"model/model_3_epoch.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f182331",
   "metadata": {},
   "source": [
    "# analyzing results and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16.53, 11.69))\n",
    "ax1.plot(history.history['accuracy'])\n",
    "ax1.plot(history.history['val_accuracy'])\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_title('Accuracy over epoch')\n",
    "ax1.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_title('Loss over epoch')\n",
    "ax2.legend(['Train', 'Test'], loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c44cc",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de6eb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for i, (image_batch, label_batch) in enumerate(test_dataset):   # use dataset.unbatch() with repeat\n",
    "    # append true labels\n",
    "    y_true.append(label_batch)\n",
    "    # compute predictions\n",
    "    preds = model.predict(image_batch)\n",
    "    # append predicted labels\n",
    "    y_pred.append(np.argmax(preds, axis =  1))\n",
    "    if i==300:\n",
    "        break\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "correct_labels = np.argmax(correct_labels, axis=1)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be581ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(correct_labels, predicted_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        figsize=(10, 10),\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, train_dataset.class_indices, cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c689b0",
   "metadata": {},
   "source": [
    "# Thank you "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
